## Java基础
### HashMap扩容
扩容时机：
1. 第一次put元素，如果是空参构造就会扩容到16
2. 当集合中的元素数量超过map的容量 * 负载因子的时候，hashmap会创建一个两倍的数组，然后将旧集合中的元素按重新计算的索引位置迁移到新数组。

### ConCurrentHashMap原理
jdk1.7主要靠分段锁实现线程安全，默认是16个segment。但是并发度取决于segment的数组大小，一旦数组初始化，大小就固定了，扩容也要所有分段一起扩，性能有限。
jdk1.8以后，concurrenthashmap就取消了segment分段锁，改为使用synchronized和CAS操作对底层数组的node节点上锁，这些被上锁的node节点也是链表或者红黑树的首节点。在执行put操作时，若节点为空，则使用CAS操作添加节点，若节点不为空，发生哈希冲突，则对首节点上锁，然后再向链表或红黑树中添加节点。get操作，无需获得锁，直接访问。并且扩容是对数组分段，使用多线程一起扩容。

### ComplateableFuture理解
异步回调类。当前使用异步线程执行任务的时候，ComplateableFuture在任务执行完后执行后续一些操作。它可以把多个任务组成一个具有先后关系的处理链，然后基于事件来驱动任务链的执行。比如thenCombine可以把两个任务组合在一起，当这两个任务都执行结束后，触发任务的回调。thencompose表示这两个串行执行。thenaccept也是串行，它可以把第一个任务的执行结果作为第二个任务的参数。thenapply它是具有返回值的thenaccept。thenrun表示第一个任务执行完后触发一个实现runnable接口的任务。

## 设计模式
- 单例模式：一个类仅有一个实例点，只提供全局唯一的访问点
- 工厂模式：用于根据传入的参数来决定创建哪种类的实例
- 观察者模式：当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并自动更新。一个类实现Observer接口作为观察者，一个类实现Observable接口作为被观察者，当被观察者发生状态变化的时候，可以调用notifyObserver方法来通知观察者。
- 策略模式：一系列功能类型、对外接口都相同的算法，并将每一个算法单独封装起来作为一种策略，通过一个上下文类来切换不同的策略，使得相同的接口在不同策略下可以实现不同的功能，比如多种支付方式。

## 锁
**synchronized锁什么**
1. 修饰普通方法，锁this，当前对象
2. 修饰静态方法，锁的就是类，类的所有对象实例
3. 修饰代码块

**synchronized原理**
无锁状态
单线程偏向型锁：将对象头的markword 标记为偏向型锁，在对象头中记录线程id
两个线程升级为轻量级锁：进来的线程通过CAS的自适应性自旋获取锁（空转会消耗CPU资源）
多个线程升级为重量级锁：竞争失败的线程会从操作系统的用户态切换为内核态，进入BLOCKED状态，由操作系统内核管理线程的阻塞和唤醒，等待锁释放被唤醒，重新进入用户态，变成RUNNING状态


**ReentrantLock和synchronized的异同**
1. 锁操作实现方式：synchronized自动获取锁释放锁，ReentrantLock手动调用API实现
2. 锁类型不同：synchronized是非公平锁，ReentrantLock默认nonfair，可以自己设置
3. 底层实现不同：synchronized是jvm通过监视器实现， ReentrantLock通过jdk基于AQS实现
4. ReentrantLock存在特性：可以给获取锁设置超时时间（trylock），可以设置锁等待过程被其他线程中断（lockInterruptibly）。可以用来监控解决死锁，通过调用线程的interrupt方法中断

**AQS**
概念：多线程同步器，JUC包中多个组件的底层实现。提供了两种锁机制：排他锁（比如ReentrantLock,只能有一个线程获取锁），共享锁（Semoaphere, CountDownLatch，同一时刻允许多个线程同时获得锁）。
三个核心问题：（1）互斥变量的设计
（2）竞争失败线程的等待及竞争成功的线程的唤醒
（3）竞争的公平性和非公平性

AQS采用int类型的state作为互斥变量记录锁竞争的状态。线程进来获取锁需要先判断state是否为0，如果是0，则更新为1，表示占用锁。同时，为了避免多线程更新的安全性，AQS采用CAS机制保证安全性。未获取到锁的线程通过Unsafe类中的park方法进行阻塞，把阻塞线程按照先进先出原则加入一个双向链表结构的等待队列。当获得锁资源的线程释放锁后，会从这样一个双向链表的头部，唤醒后续等待的线程，唤醒的线程再去竞争锁。公平性即获取锁时候需要判断等待队列是否为空，非公平性锁则是线程直接尝试修改state的值来抢锁。


## ThreadLocal
**ThreadLocal是什么**
ThreadLocal是一个线程局部变量，它可以让在多线程情况下让每个线程都独立地维护自己的变量副本，互不干扰；

**项目中的使用**
使用空参构造创建ThreadLocal，和拦截器结合使用。定义一个PROFILESThreadLocal存储每个请求的基础信息（ip，租户id，项目id）。定义一个HttpServletRequest和HttpServletResponse用于存储请求进来的请求信息和出去的响应信息。
注意项：（1）ThreadLocal类型的变量要用final修饰。Map存在于每个线程中，一个ThreadLocal对应一个值，如果ThreadLocal可变，那在改变之后就找不到原来的value了。
（2）为防止内存泄漏，在使用完ThreadLocal后，应手动调用remove()进行清除。

**原理**
每个线程内部都会维护一个ThreadLocalMap，其中存储着以ThreadLocal为key，Object为value的键值对，ThreadLocal的get()、set()操作本质上就是对线程内的这个哈希表的操作，这就保证了线程间的隔离性；由于ThreadLocalMap中使用的key是对ThreadLocal的弱引用，而value是对Object的强引用，因此在JVM进行垃圾回收的时候，key会被回收，而value不会被回收，此时就会出现key为null的Entry，除非手动清理，否则value不会被垃圾回收，就会产生内存泄漏，推荐使用完ThreadLocal之后调用remove()方法清理；

**既然可能产生内存泄漏，为什么要将ThreadLocalMap的key设计为弱引用？**
因为如果设计成强引用的话，即使线程结束销毁，其ThreadLocal中存储的Entry（包括key和value）仍不会被垃圾回收，会造成更严重的内存泄漏，
而将key设计为弱引用的话，可以保证key会被回收掉，同时调用get()、set()、remove()方法时都会清除key为null的value值，避免了内存泄漏；

**那能不能将value设计为弱引用？**
不能，因为弱引用只要JVM进行垃圾回收就会被回收掉，这就可能导致get()方法得到的是null值；

## 线程池
### 核心参数及设置
**corePoolSize**：核心线程数量，默认情况下核心线程即使空闲也不会回收，不过可以通过调用

allowCoreThreadTimeOut(true)来让核心线程也可以被回收。**CPU密集型：CPU+1，I/O密集型：CPU * 2**

**maximumPoolSize**：最大线程数 。**CPU密集型：corePoolSize，I/O密集型：>=corePoolSize * 2**

**workQueue**： 任务队列，用于存放等待执行的任务。包括`SynchronousQueue`（无缓冲队列：任务被立即执行的场景，每提交一个任务都要有空闲线程来接，否则会创建新线程或触发拒绝策略。一般适用于maximumPoolSize设置很大的场景）**、**`LinkedBlockingQueue`（无界队列：所有任务都必须被处理，吞吐量优先于响应速度的场景，会一直处于排队中，不会创建超过核心线程数的线程，容易造成OOM）、**`ArrayBlockingQueue`（有界队列：任务到来，优先由核心线程执行，核心线程满了，任务进入有界队列等待，队列也满了，则启动弹性线程，弹性线程也满了，则触发拒绝策略）**

**keepAliveTime**：超过核心线程数量的空闲线程处于空闲多长时间会被回收，一般取默认值60s即可

**handler**： 拒绝策略。
**`AbortPolicy`（默认）：抛出异常
`CallerRunsPolicy`**：由提交任务的线程（调用方线程）自己来执行这个任务。增加其他任务等待时间
**`DiscardPolicy`**：默默丢弃无法处理的任务，无任何通知。**风险高，不推荐**。
**`DiscardOldestPolicy`**：丢弃队列中最老的任务，然后尝试重新提交当前任务。**可能会导致重要任务被丢弃**。

### 如何合理设置线程池参数
1. CPU,IO固定公式
2. 根据实际情况调整，如果是占内存的任务需要结合内存使用情况。对于耗时的IO密集型任务，需要实际压测，根据结果设置线程数，防止线程数增加过多开销大。
3. 要根据业务的优先级来分配资源，核心业务占用大部分的线程数，不核心业务占用小部分，并且用无界队列存储线程。
4. 要进行监控，比如拒绝率超过5%就通知告警，再用动态线程池根据实际资源使用情况实时调整线程池参数。

### 线程池状态
RUNNING
SHUTDOWN: 不接收新任务，但是会继续处理排队的任务和正在执行的任务
STOP: 不接收新任务，不再处理排队的任务和排队中的任务
TIDYING: 过渡状态，表示即将终止，即将计入TERMINATED
TERMINATED: 完全终止

### 线程状态
**NEW**：线程被创建
**RUNNABLE**：执行中或准备执行
**BLOCKED**：线程被阻塞，等待抢锁
**WAITING**：无限期等待，需要被其他线程显式唤醒
**TIMED_WAITING**：限期等待状态，会在指定的时间后自动唤醒
**TERMINATED**：执行完成，生命周期结束

## JVM
### 分区
**程序计数器**：记录当前线程执行的字节码行号
**虚拟机栈**：存储Java方法执行的栈帧。包括局部变量表（基础数据类型和引用地址，引用地址以为指向堆中对象的内存地址）、操作数栈、动态链接、方法出口
**本地方法栈**
**堆**：存储对象实例和数组
**方法区**：类的结构信息、常量池、静态变量、即时编译器编译后的代码缓存

![[Pasted image 20251029142201.png]]


### 类加载过程
（1）加载：JVM检查该类是否已被加载，如果没有则通过类加载器进行加载。类加载器负责将类的字节码加载到内存。类加载器分为引导类加载器（BootStrapClassLoader）和自定义类加载器。自定义加载器包括ExtensionClassLoader、ApplicationClassLoader
（2）连接：验证阶段：JVM对类的字节码进行验证，确保符合Java语言规范；准备阶段：JVM为类的静态变量分配内存，并赋初始值为默认值；解析阶段：JVM将常量池中的符号引用替换为直接引用
（3）初始化：如果父类还没初始化就先初始化父类，然后执行类的初始化代码，包括静态变量赋值、静态代码块的执行和静态方法的调用
（4）创建对象：为对象分配内存空间，设置对象头信息和执行构造方法

### 双亲委派
一个类加载器在加载一个类时，首先会**将加载请求委派给父类加载器**去完成。只有当父类加载器无法完成这个加载请求时（即它在自己的搜索范围内找不到这个类），子类加载器才会尝试自己去加载。

步骤：
（1）检查是否加载过
（2）没加载过，检查父加载器是否为空，如果不为空，会去调用父类加载器的 `loadClass()` 方法，将加载请求向上传递。如果为空，则用BootstrapClassLoader加载
（3）如果父加载器加载失败，会继续由子加载器加载
（4）只有当所有的父加载器都反馈自己无法完成这个加载请求时（它们的搜索范围内没有这个类），最初的子加载器（收到请求的那个）才会调用自己的 `findClass()` 方法去尝试加载。

### GC
#### 常见的垃圾回收算法
1. 标记清除算法
**标记**：首先从GC Roots（如静态变量、栈中引用的对象等）开始，遍历所有可达对象，并对它们进行标记（通常是在对象头中记录为存活）。    
**清除**：遍历整个堆内存，将未被标记的对象（即垃圾对象）进行回收，释放其占用的内存空间。

优点：算法简单
缺点：效率低，会产生不连续的内存碎片。碎片太多会导致后续在分配较大对象时，无法找到足够的连续内存，从而不得不提前触发另一次垃圾收集

应用：ParNew、CMS(JDK 8，适合并发场景)

2. 标记整理算法
**标记**：与“标记-清除”算法一样，首先标记所有需要回收的对象。
**整理**：让所有存活的对象都向内存空间的一端**移动**，然后直接**清理掉边界以外的内存**。

优点：没有内存碎片，空间利用率高
缺点：效率低，需要移动存活对象，开销大，STW时间长

应用：老年代垃圾回收器，Parellel Old（JDK 8，并行场景）

3. 复制算法
- 将可用内存**按容量分成大小相等的两块**，每次只使用其中的一块。
- 当正在使用的这块内存用完了，就将还存活着的对象**复制**到另外一块上面。
- 然后再把已使用过的内存空间**一次性清理掉**。

优点：简单高效，只需要遍历存活对象，没有标记和清除的开销；无内存碎片
缺点：内存代价高，存活对象越多，复制成本越高

应用：新生代垃圾回收。新生代通常被划分为一个较大的Eden区和两个较小的Survivor区（From Survivor和To Survivor），其比例通常是 `8:1:1`。每次回收时，将Eden和From Survivor中存活的对象复制到To Survivor中

4. 分代收集算法
对于新生代采用复制算法，因为每次回收都有大量对象死去，成本低。对于老年代，采用标记清除或标记整理算法，如CMS+Parallel Old/G1

#### 堆
**区域划分**
新生代、老年代（Eden区，S0区、S1区，默认8:1:1）

**jvm相关参数**
-Xms: 堆的初始化内存大小
-Xmx: 堆的最大内存大小
-XX: NewRatio  老年代和新生代的比例，默认为2
-Xmn: 新生代的内存大小
**`-XX:SurvivorRatio`**: Eden区和Survivor区的比例
**`-XX:+HeapDumpOnOutOfMemoryError`**: **在发生 OOM 时自动生成堆转储文件**
**`-XX:HeapDumpPath`**: 指定堆转储文件的生成路径

G1垃圾回收器（JDK 9后默认）
**`-XX:+UseG1GC`**: 启用
**`-XX:MaxGCPauseMillis`**: **设置期望的最大 GC 停顿时间目标**（毫秒）
**`-XX:G1NewSizePercent`**，**`-XX:G1MaxNewSizePercent`**: 设置年轻代占整个堆的最小和最大比例
**`-XX:InitiatingHeapOccupancyPercent`**: **触发并发标记周期的堆占用率阈值**
**`-XX:MaxGCPauseMillis=<time>`**: **动态地调整新生代 Region（Eden Region）的数量**，如果STW时间低则会增加EdenRegion数量，让Young GC 间隔变长。如果超过STW时间，则减少EdenRegion数量


ZGC (生产环境JDK 15可用，低延迟)
**`-XX:+UseZGC`**: 启用

**项目中的相关jvm参数**
-Xmx设置为容器内存的90%
-Xms设置为最大堆内存的1/4


#### 垃圾回收过程
将新创建的对象放入年轻代的Eden区，Eden区被填满，通过标记整理算法，将对象从Eden区移入S0区，并标记GC次数。同样地，每次GC都需要将对象在Eden区、S0、S1区之前来回移动（Young GC）。Young GC有一个阈值，GC次数超过阈值后（该对象一直存活），就进行Old GC，将对象放入老年代。如果Eden区的对象大小超过Survivor区或者一开始就是超大对象，超过了年轻代的内存空间（比如大文件上传），则对象会直接放入老年代。
GC时通过可达性分析法找到存活对象，通过垃圾回收算法回收垃圾对象。

可达性分析法：以GC roots为起始点，然后一层一层找到引用的对象。
GC roots: 虚拟机栈中正在执行的方法参数、局部变量所对应的对象引用
本地方法栈中正在执行的方法参数、局部变量所对应的对象引用
方法区中保存的类信息中静态属性所对应的对象引用
方法区中保存的类信息中常量属性所对应的对象引用

#### Young GC调优
- **Eden 区过大**（Young GC 频率低）：
    - **优点**：Young GC 次数少。
    - **缺点**：每次 GC 需要处理的存活对象多，单次 STW 停顿时间可能较长；老年代晋升速度可能加快，容易引发 Full GC。
- **Eden 区过小**（Young GC 频率高）：
    - **优点**：单次 GC 停顿时间短。
    - **缺点**：GC 次数过于频繁，总体吞吐量下降。



## MySql
#### MyISAM 和 InnoDB 有什么区别
- **MyISAM** 是 MySQL 5.5 版本之前的**默认引擎**，特点是**简单、高速**，但不支持事务和外键，以**表级锁**为主。
- **InnoDB** 从 MySQL 5.5 开始成为**默认引擎**，特点是**支持事务、行级锁和外键**，提供了更佳的**崩溃恢复能力**，是生产环境的绝对首选。

#### 聚簇索引和非聚簇索引？覆盖索引？联合索引
聚簇索引就是索引结构和数据一起存放的索引，InnoDB中主键索引就是聚簇索引，其叶子节点中存储了索引结构和数据；
非聚簇索引就是索引结构和数据分开存放的索引，InnoDB中二级索引就是非聚簇索引，其叶子节点中只存储了主键；
覆盖索引：指二级索引中叶子节点存储的数据刚好可以满足本次查询所需的数据，无需使用主键再去主键索引中回表查询，这个过程就称为覆盖索引；
复合索引：创建多列的索引

```sql
CREATE INDEX idx_user_email ON users(email);
CREATE INDEX idx_name ON employees(last_name, first_name);
```

#### InnoDB中索引的底层数据结构是什么？为什么选用B+树
相比于哈希表：使用哈希表就必须一次将数据全部加载到内存中，如果数据量大就非常消耗内存，而B+树则可以按照节点分段加载，可以减少内存消耗
相比于二叉树：B+树分支更多，层级更少，IO次数更少，查询更快
相比于B树：B树非叶子结点和叶子结点都存储数据，而B+树的非叶子结点只存储索引结构，不存储数据。因此B+树每次都要查询到叶子结点才能获取到数据，而B树则可能在非叶子结点就获取数据，因此B+树查询性能更稳定。B+树的叶子结点之间通过指针顺序链接，所有叶子结点形成一个有序的双向链表，因此让范围查询变得高效，一旦找到范围起点，只需要沿着链表顺序扫描，而B树需要进行中序遍历。

#### 如何排查一条慢SQL
1. 开启慢查询日志
2. 使用EXPLAIN命令查看SQL执行计划，包括访问类型type、实际使用的索引key、预估需要扫描的行数row、额外信息extra（需要额外排序、使用临时表、在存储引擎层过滤）
3. 具体分析：比如访问类型为all添加索引，如果行数很多，考虑更严格的where条件或者分库分表，如果额外信息显示`Using filesort`，需要创建一个包含orderby字段的联合索引。如果额外信息显示`Using temporary`，需要为Groupby字段创建索引。

#### 索引优化手段
1. 使用覆盖索引，减少回表次数
2. 最左前缀原则：将最常用作查询条件的列放在复合索引的最左边
3. 避免索引列参与计算或使用函数导致其失效
4.  order by和group by字段顺序要和索引一致
5. 对于长字符串的字段使用前缀索引

#### 并发事务可能会导致哪些问题？
脏读：一个事务读到了另一个事务尚未提交的数据；
不可重复读（无幂等性）：一个事务多次读取同一数据，得到的结果却不一样；
幻读：一个事务多次使用相同的查询条件，得到的记录条数却不一样
丢弃修改：两个事务并发地对一个数据进行操作，结果产生了数据覆盖

#### 事务的隔离级别有哪些
- `READ UNCOMMITTED`（读未提交）可能导致脏读、幻读、不可重复读
- `READ COMMITTED`（读已提交）可以解决脏读
- `REPEATABLE READ`（可重复读）- **MySQL InnoDB 默认级别**，可以解决脏读、不可重复读、但是幻读侧重记录条数，不可重复读侧重内容，因此只能部分解决幻读
- `SERIALIZABLE`（串行化）解决幻读

```sql
SET TRANSACTION ISOLATION LEVEL READ COMMITTED;
START TRANSACTION;
-- ... 你的操作
COMMIT;
```

#### MVCC
MVCC（多版本并发控制）是一种用于管理数据库事务的机制，允许多个事务并发工作而不会相互干扰。相较于使用锁的方式，MVCC通过维护多个数据版本来提高并发性能.

原理：每个事务读到的不是同一个正在被修改的数据，而是自己对应的历史版本快照（读的是事务开始时刻的快照而不是当前时刻的最新数据）。所以多个事务读写互不阻塞，可以同时读同时写。
实现：（1）隐藏字段：每条数据的背后InnoDB会添加隐藏字段，包括trx_id（自增的事务id），roll_pointer（回滚指针，每次对某行数据进行修改时，会将旧版本的数据写入Undolog，这个指针就指向数据的前一个版本，形成一个版本链），DB_ROW_ID（行id，没有主键的时候生成作为聚簇索引的键）。
（2）Read View：当一个事务执行快照读的时候，会生成一个Read View，它决定这个事务能看到哪些版本的数据。原则是自己改的或者比自己早提交的能看，未提交的不能看。具体地，Read View中包含当前事务id，最小事务id，系统应该分配给下一个事务的id，生成Read View时系统中活跃（尚未提交）的所有事务id列表。如果事务id介于最小和下一个事务id之间，则需要判断其是否在活跃的事务id列表中，如果在，说明该版本事务还未提交，不可见。

#### 不同隔离级别下有什么差别
读未提交：天然就是
读已提交：每次查询都重新生成一个Read View，所以前后两次select结果可能不一样，所以会导致不可重复读。
可重复读：只在第一次查询时生成Read View，后面一直用这个快照，所以结果会保持一致。
串行：加锁

#### 如何避免幻读
对于快照读（普通select语句），MVCC就可以解决部分幻读问题
对于当前读（select ... for update语句，还有增删改操作），因为这些语句执行前都需要查询最新版本的数据，因此不能用MVCC，而是采用了记录锁+间隙锁的方式，对指定范围内的记录上锁，从而部分解决了幻读问题

极端情况下仍然会出现幻读：先快照读，再当前读。比如事务A使用快照读查询某条不存在的数据，然后事务B此时插入这条数据，事务A再使用快照读还是查不到，但是使用当前读可以查到。
怎么解决：在可重复读的隔离级别下，要给数据加行级锁。查询时不允许别的事务修改数据。


#### MySQL中有哪些锁
全局锁、表级锁、行级锁
行级锁分为记录锁（锁某一条记录）、间隙锁（锁某个范围）、临键锁（记录锁+间隙锁）

#### 在执行增删改查操作时分别会加何种锁？（默认是可重复读隔离级别）
普通select语句不加锁，MVCC就可以解决不可重复读和部分幻读问题
 select ... for share/update、update、delete会加根据可防止幻读的最小范围（符合条件的最小范围）来加记录锁、间隙锁或是临键锁
 insert操作不会加锁，但会被其他事务的间隙锁/临键锁阻塞

#### 如何解决数据库死锁
1. 设置等待锁的超时时间：当一个事务的等待时间超过该值后，就对这个事务进行回滚，释放锁。
2. 开启主动死锁检测：主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行

#### Mysql的相关日志
1. undo log：保留增删改的操作记录，方便回滚，保障原子性
2. redo log：InnoDB存储引擎实现的物理日志，记录每次数据页的修改情况并写入内存缓冲区，事务提交时，持久化到磁盘。保证事务的持久性
3. bin log：server层生成的日志，记录本次事务中执行的所有增删改操作，在事务提交的时候持久化到磁盘。用于主从复制和数据恢复

#### redo log和bin log区别
bin log是Server层实现的日志，所有存储引擎都可用，一般用于全量的数据恢复
redo log是InnoDB存储引擎实现的，有大小限制，用于处理紧急故障修复

#### 性能优化
1. 索引优化
2. SQL语句优化
3. 服务器和数据库之间使用缓存
4. 分库分表：单表数据量过大时可以用分表来减少单表数据量，高并发情况时，单个数据库难以及时处理，可以通过分库来分担并发请求
5. 读写分离：主服务器负责写，从服务器负责读


## Redis
#### 基础数据结构及应用
1. String
单个KV结构。应用：通过Set NX实现分布式锁；实现共享session：用户登录token为key，用户信息为value，设置过期时间，用户一直不登录就失效，用户一登录就给token续期；利用其原子性自增，实现计数器，比如网站访问量，点赞量等。
2. Hash
键值对集合。应用：分开存储对象不同字段，精细修改某个对象的某个属性；做购物车，用户id为key，商品id为field，商品数据为value；动态的参数管理；多维度的数据统计，视频id为key，地区为field，访问次数为value，实现不同地区视频访问量的统计。
3. List
双向链表，可重复。应用：消息队列，生产者LPUSH消息到list，消费者BRPOP阻塞式读取数据，消息者保存每次的消息id，避免重复消费；实时的消息流，用户id为key，消息id为value，发朋友圈时候写入list，别人打开展示消息，实现朋友圈动态功能。
4. Set
无序，不重复。应用：随机抽奖，利用SPOP随机返回一个元素；标签系统，一个用户的所有标签就是set；共同好友，SINTER取交集。
5. ZSet
有序，无重复，跳表结构（单层多指针的双向链表）。应用：排行榜，ZAdd添加到ZSet，ZREVRANGE
获取排行榜Top N；ip限流，ip为key，请求的时间戳为score，请求的id为value存入ZSET，统计一分钟之内某个ip的请求次数，超过阈值就进行限流。

#### 持久化机制
##### RDB
定义：数据快照，把当前Redis存的数据以二进制的形式写入RDB文件，存的是全量数据，并持久化到磁盘。
数据量大的时候保存慢怎么解决：Redis提供了两种命令来保存RDB快照，SAVE通过主线程来保存，会阻塞主线程。BGSAVE通过开一个子线程来保存。
子线程保存快照的时候，主线程还能写入或者修改数据吗：通过Copy On Write实现，Redis会把数据复制一份，主线程去修改复制的数据，子线程读取原始数据。
应用：主从复制，重启服务器恢复数据，恢复速度快

##### AOF
定义：AOF只记录写操作命令，Redis收到写命令，AOF将数据写入AOF的缓冲区在写入操作系统的内核缓冲区，在写入磁盘。
刷盘的频率：Redis提供参数设置，always（每个写命令都执行）、every Sec（每秒同步一次，默认策略）、no（不主动刷盘，由操作系统决定，容易丢失数据）
什么是AOF重写：当AOF文件膨胀到一定程度后，REdis会单独开一个子线程扫描Redis内存中的数据，生成对应的写命令然后放入到AOF文件中，这样新生成的AOF文件就缩减了。
重写如何触发：手动触发（BGREWRITEAOF），自动触发（通过参数配置，比如体积增长一倍就会自动触发）
在重写过程中如何由新的写命令怎么办：Redis主线程接受到新命令后，不仅会写入AOF缓冲区还会写入AOF重写缓冲区。子线程完成重写后，向主线程发出信号，主线程将AOF重写缓冲区的命令追加到AOF重写文件中，最后主线程原子性的将新AOF文件替换旧文件。

##### 混合持久化
RDB是全量备份，保存数据慢，但是因为二进制文件，重启后直接写入内存就可以恢复，恢复速度快。AOF因为存在缓冲区，所以保存数据快，但是恢复需要一条条执行命令，所以恢复速度慢。
定义：在AOF重写时，直接将RDB的数据写入AOF文件的开头，后面的新命令以AOF的方式写入AOF的文件中，重写后的AOF文件，前半段是RDB的二进制数据，后半段是AOF命令。这样恢复数据时，可以很快的加载前半段的RDB数据，再去执行后半段的AOF命令，这样恢复速度快也不容易丢数据。


#### 线程模型
##### 为什么单线程的Redis这么快？
1. Redis的大部分操作都是内存中的操作，且使用的数据结构很高效
2. Redis采用了单线程，避免了多线程情况下频繁的上下文切换开销
3. Redis采用了非阻塞的IO多路复用机制来处理，通过让内核同时监听多个Socket，当有连接请求或数据请求到达时，就会交给Redis线程处理，实现单线程对多个IO流的处理

#### 内存管理
##### Redis对过期数据如何处理？
1. 惰性删除：只有取出key时才对其进行过期检查。这种方式对CPU友好，但会出现大量未删除的过期数据。
2. 定期删除：每隔一段时间抽取一批key，对其进行过期检查，删除过期数据，这种方式对内存友好，但CPU负担大。
3. Redis采用混用的方式

##### Redis如果内存溢出怎么办
当Redis运行内存达到设置的最大运行内存（默认情况下64位操作系统无限制，32位为3G），就会触发内存淘汰机制，主要有8种方式，可以分为三类，
1. 不做内存淘汰（默认）：`noeviction`（新写入的数据会报错）
2. 对设置了过期时间的数据进行淘汰：`volatile-random（从设置了过期时间的键中，随机移除某个键。）`、`volatile-ttl`（从**设置了过期时间**的键中，移除**剩余存活时间最短**的键）、`volatile-lru`（设置了过期时间的键中，移除最近最少使用的键）、**volatile-lfu**（从**设置了过期时间**的键中，淘汰在最近一段时间内，使用频率最低的键）
3. 对全部数据进行淘汰：`allkeys-random`（从所有键中随机淘汰一个）、`allkeys-lru`（从所有键中，移除最近最少使用的键。）、**allkeys-lfu**（从所有键中淘汰在最近一段时间内，使用频率最低的键）
**LRU** 关注的是 **“最近多久没被访问”**
**LFU** 关注的是 **“一段时间内的访问次数“**

#### 主从复制、哨兵和集群原理
##### 主从复制
主服务器执行写操作，从服务器执行读操作。通过主从复制把主服务器的数据复制到从服务器。
主从复制分为全量复制（新启动的从服务器没有数据，就需要复制主服务器的数据给从）和增量复制（如果从服务器断连一段时间又重新连接，可以根据偏移量将断连期间主服务器执行的写命令传给从服务器）
全量复制：主通过BGSAVE命令生成RDB文件，把该文件发给从，从服务器收到后清空当前数据，加载RDB文件到内存中。
增量复制：全量复制后，之后主从服务器之间会维护一个长连接，当主服务器收到了写命令时，也会将写命令通过连接传给从服务器，保证主从服务器的数据一致性。

缺点：如果主服务器宕机，只能通过手动选择从服务器来取代主服务器，响应缓慢

##### 哨兵模式
在主从复制的基础上，通过新增几个哨兵节点，专门用于监控主从服务器的运行状态，当主服务器宕机时，自动选出一个从服务器取代主服务器，保证Redis服务的可用性
哨兵节点（三个以上）会每隔一秒就给所有服务器发送PING命令，如果某个服务器超过一段时间未回复，则本哨兵认为此服务器已下线，称为主观下线。此哨兵会通知其他哨兵上报监控情况（投票机制），如果认为该服务器主观下线的数量达到一定数量即多数哨兵都认为主观下线，就认为这个服务器客观下线，此时哨兵节点会选出其中一个哨兵作为leader，来进行接下来的故障转移：**首先根据每个从节点的优先级、对主服务器数据的复制进度、节点id来选出新的主节点（如果前面两个相同，则节点id越小，就会成为主），然后令其他从服务器都指向这个新的主服务器，并通知客户端主从倒换。最后当发生故障的原主服务器重新上线时，将其转换为从服务器指向新的主服务器。**

缺点：哨兵和主从复制都只能缓解主服务器的读压力，但在高并发场景下写压力也很大，需要缓解


##### 集群
通过部署多台master，同时对外提供读写服务，让缓存数据库均匀地分布在这些master节点上，客户请求会根据路由规则发送到目标master节点上，缓解了高并发场景下的写压力，解决单机数据量大的问题。同时每台master都配备了若干salve节点并内置了哨兵机制，在master发生故障时自动完成故障转移。

**如何实现数据分片**：Redis集群采用了哈希槽算法来对缓存数据库分配给各master节点，总共有2^14=16384个哈希槽，通过对key值计算CRC-16校验码，再对16384取模，将其分配到其中一个哈希槽，再根据哈希槽和master节点的对应关系寻址到对应的master节点进行操作；——哈希槽算法的优点是当新增或删除节点时，只需要改变哈希槽和master节点的对应更新即可，key值和哈希槽的对应关系保持不变。

**节点间如何通信**：各节点基于Gossip协议进行通信并维护一份集群内各节点的状态信息，比如发送meet消息通知新节点加入，节点向集群中其他节点周期性发送ping消息。其他节点收到ping或meet消息后响应pong消息。某个节点被多数节点标记为下线时发送fail消息。

#### 缓存穿透、缓存击穿、缓存雪崩
缓存穿透：某个key查询不存在，大量请求直接打在数据库上。解决方法：暂时缓存空值，设置过期时间；使用布隆过滤器判断key是否存在于数据库，不存在则丢弃请求
缓存击穿：高并发情况下某个热点key突然失效，大量请求直接打在数据库上。解决办法：针对热点key提前预热，将其存入缓存中并设置合理的过期时间。设置热点key的过期时间很长或永不过期
缓存雪崩：缓存服务器宕机，或是同一时间内大量缓存过期，导致大量请求全部落在了数据库上，导致数据库崩溃。解决办法：使用Redis集群保证Redis服务的高可用性，限流防止过量请求访问

布隆过滤器：底层就是一个位数组和若干个哈希函数，当有元素加入时，就通过这几个哈希函数计算元素的哈希值，并将位数组的对应位置修改为1。当需要判断元素是否存在时，同样通过这几个哈希函数计算元素的哈希值，得到对应位置位数组的值并做与运算，如果均为1则认为此元素存在，反之认为不存在。 

#### 生产问题
大key：定义String类型大小超过10kb，其他类型元素数量超过5000个
解决办法：使用监控工具比如prometheus、Grafana监控是否存在大key，使用分批次删除大key。进行数据压缩（GZIP）。设置合理的过期时间和清除策略。设置内存淘汰策略。

热key：一个key在一段时间内的访问次数明显高于其它key，就认为它是热key。
解决办法：使用redis自带的hotkeys参数或者借助开源软件来找到热key，使用二级缓存（添加一级本地缓存）缓解redis压力。

## Spring
#### IOC和DI
控制反转的思想（Inversion of Control），传统的java开发里面我们只能通过new来创建对象，这样会导致高耦合，对象依赖复杂。而IOC容器的主要作用就是实现了对象的管理，把设计好的对象交给IOC容器来控制，然后在需要用到对象的地方直接从容器中获取。IOC把对象的创建和查找依赖对象的控制交给了容器，实现了对象之间的松耦合。DI表示依赖注入，对于IOC容器中管理的bean，如果bean之间存在依赖关系，那么IOC容器需要自动去实现依赖对象的实例注入，有三种方式去描述bean和bean之间的依赖关系，包括接口注入，setter注入，构造器注入。


#### Bean注入方式
1. @Autowired
直接注入，根据类型。@Resource根据name。当有多个同类型的 Bean 时，仅用 `@Autowired` 会产生歧义，需要用 `@Qualifier` 指定 Bean 的名称
2. Setter注入
注入到Setter方法
```java
@Autowired // 注入到 Setter 方法
    public void setUserService(UserService userService) {
        this.userService = userService;
    }
```
3. 构造器注入
保证依赖在bean创建的时候就完全初始化。方便单元测试。依赖可以是 `final` 的，保证了不变性和线程安全
```java
// @Autowired 可省略
    public UserController(UserService userService, EmailService emailService) {
        this.userService = userService;
        this.emailService = emailService;
    }
```
4. Java Config 配置类注入 
使用 @Configuration 类和 @Bean 方法显式地定义和装配 Bean。

#### @Autowired和@Resource注解区别
1. Autowired来自Spring框架，Resource来自jdk
2. Autowired按类型匹配，类型相同需要借助Qualifier注解指定名称，Resource按名称匹配，相同再根据类型
3. @Autowired支持属性、setter方法和构造器注入，@Resource只支持属性、setter方法

#### Spring IoC实现的原理
主要有两阶段，第一阶段完成容器的创建和Bean的加载和注册，第二阶段完成Bean的初始化。
第一阶段，首先创建一个BeanFactory的实现类的实例对象作为容器，这个容器包含一个以Beanid为key，BeanDefinition为value的ConcurrentHashMap，叫做beanDefinitionMap，用于存放当前容器中注册的全部Bean的信息，还有一个按注册顺序存储Bean id的ArrayList，叫beanDefinitionNames；读取并解析xml配置文件并将各个bean解析成BeanDefinition对象，和beanid一起注册到容器的集合和哈希表中。
第二阶段，主要完成对单例、非懒加载的Bean的初始化，具体来说，在容器中有一个以Bean id 为key、以Bean实例对象为value的ConcurrentHashMap，叫singletonObjects，这个哈希表专门用于存放单例对象，在进行Bean初始化时会先查询这个哈希表，若对象存在则直接返回，若不存在则通过 **反射** 调用其构造函数来创建对象并与其id一起存入singletonObjects中，后面使用getBean()方法获取实例对象时，也是先查询singletonObjects。

#### Spring AOP
定义：AOP就是将非业务的公共代码，比如日志记录、权限控制、异常处理等封装在一起，使用切点标注使用的代码位置，使用Before、After等注解标注方法的执行时机，实现松耦合，可扩展性。

#### AOP代理方式
Spring AOP是基于动态代理实现的，对于有接口的对象，使用JDK Proxy来代理。对于没有接口的对象，使用Cglib来代理。也可以通过启用加载时织入使用AspectJ框架。从 Spring Boot 2.0 开始，默认统一使用 **CGLIB**，因为这样可以直接代理类而不限于接口。

#### Spring AOP 和 AspectJ AOP 有什么区别
1. 本质：Spring AOP 基于代理，而 AspectJ 基于字节码操作
2. 织入时机：Spring AOP是运行时织入，AspectJ是编译时织入
3. 性能：Spring AOP因为使用代理和反射，有一定开销，AspectJ性能更高
4. 复杂度：Spring AOP更轻量，和Spring融合，AspectJ功能更强大但是更复杂，需要额外的构造步骤

#### Spring MVC
Spring MVC是对传统MVC模式的实现和扩展，传统MVC分为Model、View、Controller。而在Spring体系中，这三层被进一步的细化和分工，业务逻辑放在service层，数据访问放在Repository层，Web层由Controller层控制。Web层采用前端控制模式，是对Servlet api的封装，由DispatcherServlet统一接收所有请求，再根据请求映射规则分发给后端控制器Controller。控制器执行完逻辑后返回一个ModelAndView对象，再交由ViewResolver去解析视图，最终渲染成HTML页面。但是如果添加了RestController注解，Spring MVC就把对象转换成json或者xml，返回给前端，实现前后端分离。

#### SpringBoot自动装配
自动装配指的是在引入starter后，只需要通过少量注解和配置就可以使用第三方组件提供的功能了。
Springboot的启动类注解SpringBootApplication中核心依赖注解EnableAutoConfiguration，其内部导入一个类AutoConfigurationImportSelector，这个类会通过SpringFactoriesLoader扫描项目所有依赖包下的META-INF/spring.factories文件，这些文件包含的是配置类，当然通过注解中的exclude参数排除的配置类不处理。Springboot启动时会把这些配置类按需加载进来，完成自动装配（满足才配置，要兼顾Conditional注解）。


## MyBatis
#### Mapper接口/DAO接口的工作原理是什么？为什么没有实现类也能实现功能？
mapper接口的工作原理是jdk动态代理，Mybatis在运行时会为mapper接口生成代理对象，代理对象会拦截接口方法。转而去执行xml配置文件中的sql语句，返回结果。

#### 如何使用MyBatisPlus实现分页功能
1. 新建一个Mybatisplus的配置类
2. 在上述配置类里创建一个分页拦截器的bean
3. 单表查询：使用页面大小和当前页数作为参数创建一个Page对象，将这个对象同查询条件一起传入BaseMapper提供的selectPage()方法即可实现分页条件查询，查询结果也会以Page的形式返回
4. 复杂查询：mapper接口中自定义IPage方法，并在xml中自定义sql，插件会自动分页

#### 分页原理
首先MyBatisPlus的分页拦截器会拦截所有sql语句的执行，对sql语句进行解析并判断传入的参数中是否有Page分页对象，如果没有就放行，如果有就根据page参数的当前页数和页面大小给sql语句拼接limit分页语句。

#### MyBatis-Plus相比MyBatis有什么区别？
1. MyBatis-Plus是在MyBatis基础上的增强
2. 提供了BaseMapper接口，实现该接口后，就可以使用内置的CRUD函数，省去了在xml中编写sql的麻烦
3. 提供了分页插件，只需要使用selectpage方法，通过page对象就可以实现分页查询
4. 提供了@TableName、@TableId这样的注解，更方便实现实体类与数据库表的映射

## Zookeeper
#### 基本架构是什么
ZooKeeper 是一个典型的分布式、开源的数据协调服务，他是一个以 Leader 为核心、Follower 和 Observer 协同工作的主从集群，通过 ZAB 协议保证数据强一致性，对外提供了一棵基于 ZNode 的树形数据模型，并辅以一次性的 Watch 监听机制，从而高效可靠地解决了分布式环境下的各类协调问题。

#### Zookeeper的节点数据结构是什么样
ZooKeeper的节点数据结构可以概括为 一棵类似于标准文件系统的树形结构，树上的每个节点称为ZNode。每个 ZNode 都通过一个绝对路径来唯一标识。并且每个 ZNode 可以存储少量数据（默认上限 1MB），通常用于存储配置、状态等元信息。他有两种类型，临时节点和持久节点，临时节点就是客户端会话结束后就主动删除节点。还有顺序节点，ZooKeeper会在其路径后附加一个单调递增的序列号zxid。举个例子，比如我们有个注册中心，路径是/service，当一个服务启动时，他会在/service下面创建一个临时节点，并在该节点的数据区存储自己的服务地址。当这个服务宕机时，就会结束和zookeeper的会话，这个节点会被自动清理掉，实现服务下线。而这个服务的消费者只要监听/service的子节点的变化，就可以实时感知所有可用的服务实例。

#### 工作原理
读请求可以由任何 Follower 或 Observer 处理，但是写请求只能通过leader处理。客户端向leader发送写请求，leader会将请求以事务的形式放入fifo队列，然后发送给各个follower，follower收到写请求后，会以事务的形式写入本地磁盘并返回ack给leader，leader收到超过半数的ack后，会广播一个commit消息给所有的follower和observer，leader再提交事务，返回结果给客户端，follower收到commit后完成对事务的提交。

#### watch机制是什么样的
客户端可以在指定的 ZNode 上注册一个 Watch，监听其变化（如数据变更、子节点列表变更、节点删除等）。当znode发生变化后，会通知客户端。一般用来监听感兴趣的事件，但是watch是一次性的，触发后就会生效，每次都需要重新注册。

#### 会话机制是什么样的
客户端和zookeeper集群之间维系一个TCP长连接，会话在第一次连接建立后就一直存在，之后是通过心跳检测来维护会话状态。但是每个会话都有一个超时时间，如果超时时间内服务器没有收到任何请求，会话就会过期，所有相关的临时znode节点就会删除。

#### ZAB协议
ZAB协议是维持Zookeeper数据一致性和高可用的关键。正常状态下，leader会为每个写请求生成一个全局唯一，递增的zxid，然后将zxid广播给follower，当leader收到超半数的follower的ack后，就执行commit广播给各个follower和observer，将结果返回客户端，同时follower也提交该事务。异常状态下，leader宕机，需要选举新的leader，原则是新的leader必须是已经提交了之前所有的事务请求（有最大zxid节点）。超过半数投票则选举成功，新选举的leader会与所有follower进行数据同步，丢弃所有未提交的事务，同步完成后退出选举模式。


## kafka
#### 基本架构是什么
kafka的基础架构是一个高吞吐、高可用的分布式，基于发布-订阅模型模式的消息系统。kafka集群包括生产者集群、消费者集群、broker集群和一个zookeeper集群。生产者负责创建消息将其发送到指定的topic。消费者负责订阅topic，从topic中拉取消息进行处理。broker是独立的kafka服务器节点，负责接收生产者的消息，持久化到磁盘，处理消费者拉取的请求。ZK就是注册中心，用来管理broker集群，去保存这个topic和partition的路由信息。topic就是消息的类别，每个topic又分为多个partition分布式存储消息，实现并行读写。partition中的每条消息都会分配一个唯一的，递增的id，称为offset，他记录消息在分区中的位置来跟踪消费进度。一个topic下的不同的partition可以分配到不同的broker节点上。


#### 工作流程
首先broker集群定期向ZK发送心跳包，上报消息，ZK掌管了所有broker topic和partition的信息。broker集群会选举出controller，监听ZK中topic的变化，一旦topic变化，他就会向ZK拉取最新数据然后广播给各个broker。生产者通过访问broker就能获取到路由信息，然后根据配置的路由策略把消息发送给目标topic对应的leader partition所在的broker，broker收到消息后，写到partition末尾然后分配offset，并且leader partition此时会同步数据给副本。消费者访问broker获取到topic的路由信息，然后通过自己记录的最新的offset就可以去读取消息。


#### kafka如何实现高可用
kafka提供了多副本机制，每个partition都会同步到其他的broker节点上，在多个partition副本中会选举出一个leader，处理读写请求，其他follower只负责异步地同步数据。leader发生故障时，会自动选举leader。

#### 为什么leader处理读写请求，follower只负责备份数据
如果读follower的话，offset很难管理。

#### 消费者组
多个消费者实例组成一个消费者组，每个partition只能被一个消费者实例消费，一个消费者实例可以消费多个partition。所有消费者在同一个组内，消息被平均分配，每条消息只能被一个消费者处理。从而实现消息的并行处理。

#### 重平衡
Rebalance。消费者组内某个消费者实例挂掉后或者有新加入的消费者实例，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。

#### ack不同值分别代表什么
acks 参数指定了要有多少个分区副本接收消息，生产者才认为消息是写入成功的。
acks=0：生产者也不知道自己产生的消息是否被服务器接收了，类似UDP。
acks=1：只要集群的 Leader 接收到消息，就会给生产者返回一条消息，告诉它写入成功。分为同步和异步消息发送。
acks= all：只有当所有参与复制的副本都收到消息时，生产者才会接收到一个来自服务器的消息。

#### 消费者消息提交方式
1. 自动提交
最简单的方式就是让消费者自动提交偏移量。如果 `enable.auto.commit` 被设置为true，那么每过 5s，消费者会自动把从 poll() 方法轮询到的最大偏移量提交上去。
2. 提交当前偏移量
把 `auto.commit.offset` 设置为 false，可以让应用程序决定何时提交偏移量。使用 `commitSync()` 提交偏移量。这个 API 会提交由 poll() 方法返回的最新偏移量，提交成功后马上返回，如果提交失败就抛出异常。

#### 三大MQ对比
RabbitMQ比Kafka可靠，kafka更适合IO高吞吐的处理，一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用，比如ELK日志收集。而RocketMQ是高吞吐，高可用的。


## IO
#### 什么是IO多路复用
I/O多路复用是一种**使用单个线程（或少量线程）来同时监听多个文件描述符（如网络连接）的I/O就绪状态的机制**。它的核心思想是由内核负责通知用户线程哪些连接已经就绪（可读、可写或异常），从而避免创建大量线程来阻塞等待，极大地提升了高并发场景下的程序性能。epoll原理是在内核中维护一棵红黑树来存放监控的连接，还在内核中使用一个链表还存放发生事件的连接，不用重复遍历。而select/poll是使用线性结构来存储要监控的连接，然后将集合拷贝到内核，内核通过遍历集合查找到哪些是有事件发生的连接，在拷贝回用户态，用户态再次遍历找到有事件发生的连接返回给线程。

#### BIO和NIO区别
BIO：当线程发起read调用，如果内核没有准备好数据，线程会进去阻塞状态。直到内核准备好数据，再由同步或者异步来决定由谁将数据拷贝到用户态。
NIO：当线程发起read调用，如果内核没有准备好数据，线程不会进入阻塞状态，而是去执行其他操作。同时轮询地向内核发起read调用，待内核准备好数据，在根据同步还是异步决定谁将数据拷贝到用户态（同步就是由线程自己来执行，异步就是由内核执行，线程只需要处理拷贝好的数据）。

#### 什么是Reactor模式
Reactor是一种同步非阻塞网络模式，IO多路复用负责监听连接和获取发生事件的连接，Reactor则是负责在收到事件后，根据事件类型分配给对应的模块进行处理；
 单Reactor单线程：主要分为Reactor、Acceptor、Handler三部分，Reactor负责接收和分发事件，Acceptor负责处理建立连接的事件，Handler负责处理其他事件例如读写操作等；
 单Reactor多线程：主线程管理Reactor、Acceptor、Handler，但区别在于此时Handler不再负责处理任务，而是将任务交给线程池中的某个子线程处理，Handler只负责转发数据；
 多Reactor多线程：主线程只管理一个主Reactor和Acceptor，负责处理连接事件和将连接分配给一个子线程（不再负责分发事件，而是改为分配连接），每个子线程都有自己的副Reactor和Handler，会继续监听连接并当发生事件时分发给自己的Handler来处理事件；
